var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput');document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"/docs/technologies/introduction/",title:"Introduction",description:"Information about specific technologies",content:'\u003ch3 id="text-to-speech"\u003eText-To-Speech\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/tts/"\u003eTTS Docs →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="speech-to-text"\u003eSpeech-To-Text\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/stt/"\u003eSTT Docs →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="ocr"\u003eOCR\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/ocr/"\u003eOCR Docs →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="nlp"\u003eNLP\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/nlp/"\u003eNLP Docs →\u003c/a\u003e\u003c/p\u003e\n'},{id:1,href:"/docs/technologies/tts/",title:"Text-To-Speech",description:"Information about TTS",content:'\u003ch3 id="text-to-speech"\u003eText-To-Speech\u003c/h3\u003e\n\u003cp\u003eTBA: More infor about TTS.\u003c/p\u003e\n'},{id:2,href:"/docs/technologies/stt/",title:"Speech-To-Text",description:"Information about STT",content:'\u003ch3 id="hugging-face-wav2vec2"\u003eHugging Face wav2vec2\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe Wav2Vec2 model was proposed in \u003ca href="https://arxiv.org/abs/2006.11477"\u003ewav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations\u003c/a\u003e\nby Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003efrom \u003ca href="https://huggingface.co/transformers/model_doc/wav2vec2.html"\u003eModel Documentation\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003ePretrained Models\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eShahu Kareem\u0026rsquo;s result using Common Voice data, from Hugging Face model training week:\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://huggingface.co/shahukareem/wav2vec2-large-xlsr-53-dhivehi"\u003eFull Model\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eQuantized Model: gdown \u0026ndash;id \u003ccode\u003e1m6QXhMF9Zf6P04Z1D2qFiQjEFo16Vexv\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="mozilla-deepspeech"\u003eMozilla DeepSpeech\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDeepSpeech is an open-source Speech-To-Text engine, using a model trained by machine\nlearning techniques based on Baidu\u0026rsquo;s Deep Speech research paper.\nProject DeepSpeech uses Google\u0026rsquo;s TensorFlow to make the implementation easier.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe toolchain has been show to work well. A pretrained model is unavailble at this time.\u003c/p\u003e\n'},{id:3,href:"/docs/technologies/nlp/",title:"NLP",description:"Information about NLP",content:'\u003ch3 id="dhivehi_nlp"\u003edhivehi_nlp\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePython library with various natural language processing tools for Dhivehi. Modules include tokenizer, stopwords, stemmer, language models, dictionary, corpus, trigram similarity and tagger.\u003c/p\u003e\n\u003cp\u003eLanguage models module also includes a bigram language model based on a news dataset.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://github.com/mismaah/dhivehi_nlp"\u003eSource Code\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://dhivehi-nlp.herokuapp.com/"\u003eDemo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://dhivehi-nlp.herokuapp.com/docs/index.html"\u003eDocumentation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:4,href:"/docs/technologies/ocr/",title:"OCR",description:"Information about OCR",content:'\u003ch3 id="ocr"\u003eOCR\u003c/h3\u003e\n\u003cp\u003eTBA: More info about OCR.\u003c/p\u003e\n'},{id:5,href:"/docs/datasets/speech/",title:"Speech Datasets",description:"Collection of speech data",content:'\u003ch3 id="mozilla-common-voice"\u003eMozilla Common Voice\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCommon Voice is Mozilla\u0026rsquo;s initiative to help teach\nmachines how real people speak.\nThe project is currently active and collective data from\ncontributors.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://commonvoice.mozilla.org/dv/datasets"\u003eDownload latest data\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="presidential-speeches"\u003ePresidential Speeches\u003c/h3\u003e\n\u003cp\u003eDhivehi speech data - data collected from PO MV (* 1 GB).\nExtracted and processed by \u003ca href="https://github.com/Sofwath"\u003eSofwath\u003c/a\u003e\nas part of a collection of Dhivehi datasets found \u003ca href="https://github.com/Sofwath/DhivehiDatasets"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://drive.google.com/file/d/1vhMXoB2L23i4HfAGX7EYa4L-sfE4ThU5/view?usp=sharing"\u003eDownload from Google Drive\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:6,href:"/docs/datasets/text/",title:"Text Datasets",description:"Collection of text data",content:'\u003ch3 id="quran-translation"\u003eQuran Translation\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDhivehi Quran translation source files.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://github.com/kudanai/Quran-Translation"\u003eLink to GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="leipzig-university-corpora-collection"\u003eLeipzig University Corpora Collection\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe Leipzig Corpora Collection provides different tools and\ndata for download, which are protected by copyright.\nFor more details please refer to our\n\u003ca href="https://wortschatz.uni-leipzig.de/en/usage"\u003eterms of usage\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://cls.corpora.uni-leipzig.de/en/div_newscrawl_2015_300K/"\u003eCorpora Stats\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://wortschatz.uni-leipzig.de/en/download/Dhivehi"\u003eLink to Website\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:7,href:"/docs/datasets/ocr/",title:"OCR Datasets",description:"Collection of speech data",content:'\u003ch3 id="dash8x-thaana-dataset"\u003eDash8x Thaana-Dataset\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA dataset of handwritten and computer generated Thaana glyphs\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://github.com/dash8x/Thaana-Dataset"\u003eLink to GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id="akuru-mnist"\u003eAkuru-MNIST\u003c/h3\u003e\n\u003cp\u003eFrom Sofwaths collection \u003ca href="https://github.com/Sofwath/DhivehiDatasets"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAkuru-MNIST is a MNIST style akuru dataset for OCR (* 161 MB)\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://drive.google.com/file/d/16LSVcNcoPmaMPTkisOned9rl61YwfZKB/view?usp=sharing"\u003eLink to Google Drive\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:8,href:"/docs/tools/useful_tools/",title:"Useful Tools",description:"A Collection of useful tools",content:""},{id:9,href:"/docs/external/publications/",title:"Publications",description:"External publications",content:""},{id:10,href:"/docs/datasets/",title:"Datasets",description:"Links to datasets",content:""},{id:11,href:"/docs/external/",title:"External Resources",description:"Links useful external resources.",content:""},{id:12,href:"/docs/tools/",title:"Tools",description:"Various tools and resources",content:""},{id:13,href:"/docs/technologies/",title:"Technologies",description:"Overview of tech projects",content:""},{id:14,href:"/docs/",title:"Resources",description:"dhivehi.ai Resources",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()