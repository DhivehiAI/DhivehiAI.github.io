var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput');document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"/docs/technologies/introduction/",title:"Introduction",description:"Information about specific technologies",content:'\u003ch3 id="text-to-speech"\u003eText-To-Speech\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/tts/"\u003eTTS Docs →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="speech-to-text"\u003eSpeech-To-Text\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/stt/"\u003eSTT Docs →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="ocr"\u003eOCR\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/ocr/"\u003eOCR Docs →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="nlp"\u003eNLP\u003c/h3\u003e\n\u003cp\u003e\u003ca href="/docs/technologies/nlp/"\u003eNLP Docs →\u003c/a\u003e\u003c/p\u003e\n'},{id:1,href:"/docs/technologies/tts/",title:"Text-To-Speech",description:"Information about TTS",content:'\u003ch3 id="text-to-speech"\u003eText-To-Speech\u003c/h3\u003e\n\u003cp\u003eTBA: More infor about TTS.\u003c/p\u003e\n'},{id:2,href:"/docs/technologies/stt/",title:"Speech-To-Text",description:"Information about STT",content:'\u003ch3 id="speech-to-text"\u003eSpeech-To-Text\u003c/h3\u003e\n\u003cp\u003eTBA: More info about STT.\u003c/p\u003e\n'},{id:3,href:"/docs/technologies/nlp/",title:"NLP",description:"Information about NLP",content:'\u003ch3 id="nlp"\u003eNLP\u003c/h3\u003e\n\u003cp\u003eTBA: More info about NLP.\u003c/p\u003e\n'},{id:4,href:"/docs/technologies/ocr/",title:"OCR",description:"Information about OCR",content:'\u003ch3 id="ocr"\u003eOCR\u003c/h3\u003e\n\u003cp\u003eTBA: More info about OCR.\u003c/p\u003e\n'},{id:5,href:"/docs/datasets/speech/",title:"Speech Datasets",description:"Collection of speech data",content:'\u003ch3 id="mozilla-common-voice"\u003eMozilla Common Voice\u003c/h3\u003e\n\u003cp\u003eCommon Voice is Mozilla\u0026rsquo;s initiative to help teach machines how real people speak.\nThe project is currently active and collective data from\ncontributors.\u003c/p\u003e\n\u003cp\u003e\u003ca href="https://commonvoice.mozilla.org/dv/datasets"\u003eDownload latest data\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="presidential-speeches"\u003ePresidential Speeches\u003c/h3\u003e\n\u003cp\u003eDhivehi speech data - data collected from PO MV (* 1 GB).\nExtracted and processed by \u003ca href="https://github.com/Sofwath"\u003eSofwath\u003c/a\u003e\nas part of a collection of Dhivehi datasets found \u003ca href="https://github.com/Sofwath/DhivehiDatasets"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href="https://drive.google.com/file/d/1vhMXoB2L23i4HfAGX7EYa4L-sfE4ThU5/view?usp=sharing"\u003eDownload from Google Drive\u003c/a\u003e\u003c/p\u003e\n'},{id:6,href:"/docs/datasets/text/",title:"Text Datasets",description:"Collection of text data",content:'\u003ch3 id="quran-translation"\u003eQuran Translation\u003c/h3\u003e\n\u003cp\u003eDhivehi Quran translation source files.\u003c/p\u003e\n\u003cp\u003e\u003ca href="https://github.com/kudanai/Quran-Translation"\u003eLink to GitHub\u003c/a\u003e\u003c/p\u003e\n'},{id:7,href:"/docs/datasets/ocr/",title:"OCR Datasets",description:"Collection of speech data",content:'\u003ch3 id="dash8x-thaana-dataset"\u003eDash8x Thaana-Dataset\u003c/h3\u003e\n\u003cp\u003eA dataset of handwritten and computer generated Thaana glyphs\u003c/p\u003e\n\u003cp\u003e\u003ca href="https://github.com/dash8x/Thaana-Dataset"\u003eLink to GitHub\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="akuru-mnist"\u003eAkuru-MNIST\u003c/h3\u003e\n\u003cp\u003eAkuru-MNIST is a MNIST style akuru dataset for OCR (* 161 MB),\nfrom Sofwaths collection \u003ca href="https://github.com/Sofwath/DhivehiDatasets"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca href="https://drive.google.com/file/d/16LSVcNcoPmaMPTkisOned9rl61YwfZKB/view?usp=sharing"\u003eLink to Google Drive\u003c/a\u003e\u003c/p\u003e\n'},{id:8,href:"/docs/tools/useful_tools/",title:"Useful Tools",description:"A Collection of useful tools",content:""},{id:9,href:"/docs/external/publications/",title:"Publications",description:"External publications",content:""},{id:10,href:"/docs/datasets/",title:"Datasets",description:"Links to datasets",content:""},{id:11,href:"/docs/external/",title:"External Resources",description:"Links useful external resources.",content:""},{id:12,href:"/docs/tools/",title:"Tools",description:"Various tools and resources",content:""},{id:13,href:"/docs/technologies/",title:"Technologies",description:"Overview of tech projects",content:""},{id:14,href:"/docs/",title:"Resources",description:"dhivehi.ai Resources",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()