---
title: "Speech-To-Text"
description: "Information about STT"
lead: "Information about Speech-To-Text tech"
date: 2020-10-06T08:48:57+00:00
lastmod: 2020-10-06T08:48:57+00:00
draft: false
images: []
menu:
  docs:
    parent: "technologies"
weight: 102
toc: true
---

### Hugging Face wav2vec2

> The Wav2Vec2 model was proposed in [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477)
by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.
>
> _from [Model Documentation](https://huggingface.co/transformers/model_doc/wav2vec2.html)_


**Pretrained Models**:
  * Shahu Kareem's result using Common Voice data, from Hugging Face model training week:
    * [Full Model](https://huggingface.co/shahukareem/wav2vec2-large-xlsr-53-dhivehi)
    * Quantized Model: gdown --id `1m6QXhMF9Zf6P04Z1D2qFiQjEFo16Vexv`

### Mozilla DeepSpeech

> DeepSpeech is an open-source Speech-To-Text engine, using a model trained by machine
> learning techniques based on Baidu's Deep Speech research paper.
> Project DeepSpeech uses Google's TensorFlow to make the implementation easier.

The toolchain has been show to work well. A pretrained model is unavailble at this time.
